
# Oveview
In this project, traditional explainability methods based on LIME, SHAP, and DICE were compared to an approach that combined ANOVA
decomposition and LASSO regularization. These strategies were applied across a spectrum of machine learning
models tailored for a linear regression problem.. Please note that I collaborated with other individuals as co-authors for these projects.

## EXPLANATION TECHNIQUES FOR BLACK BOX MACHINE LEARNING MODELS
- **Description:** This project tests the most famous explainability techniques (Lime, Dice and Shap) together with a custom Anova-based explainability algorithm. This study is based on the models defined and optimized by another team at the University of Bologna, working with data coming out of a "robot dance evaluation performance". More details are presented in the report.
- **Technologies:** Python, Dice, Lime, Shap, ANOVA.
- **My contributions:** For this project, my primary focus was on implementing the SHAP explanations. Additionally, I made contributions to the development of the custom ANOVA algorithm and to the following study related to the ANOVA assumptions.
- **Results:** The study explains why the ANOVA assumptions do not hold for any kind of data, and in particular why the algorithm based on it is not ok for this dataset, and provides an overview on the most important features for the "robot dance performance evaluation".
